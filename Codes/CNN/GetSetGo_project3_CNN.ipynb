{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "import scipy.misc # to visualize only\n",
    "x = numpy.fromfile('dataset/train_x.bin', dtype='uint8')\n",
    "x = x.reshape((100000,60,60))\n",
    "x[x<255] = 0\n",
    "\n",
    "#scipy.misc.imshow(x[10]) # to visualize only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import h5py\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the input data has been transformed to the form 1,60,60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv('dataset/train_y.csv')\n",
    "y=y['Prediction']\n",
    "y=y.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.3, random_state=42)\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1,60,60).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1,60,60).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalise the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the model with the different convolutions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Layer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(32, 7, 7, border_mode='valid', input_shape=(1, 60, 60), activation='relu'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "#\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Convolution2D(32, 5, 5, activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Convolution2D(64, 5, 5, activation='relu'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Convolution2D(128, 5, 5, activation='relu'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dropout(0.2))\n",
    "#\tmodel.add(Dense(256, activation='relu'))\n",
    "\tmodel.add(Dense(256, activation='relu'))\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-Layer Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(64, 7, 7, border_mode='valid', input_shape=(1, 60, 60), activation='relu'))#54\n",
    "#\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Convolution2D(64, 5, 5, activation='relu'))#50\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))#25\n",
    "\tmodel.add(Convolution2D(64, 5, 5, activation='relu'))#21\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#19\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))#9\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "#\tmodel.add(Dense(256, activation='relu'))\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11-Layer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(64, 3, 3, border_mode='valid', input_shape=(1, 60, 60), activation='relu'))#58\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#56\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))#28\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#26\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#24\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))#12\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#10\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#8\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))#4\n",
    "\tmodel.add(Convolution2D(64, 3, 3, activation='relu'))#2\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))#1\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu',W_regularizer=l2(0.01)))\n",
    "\tmodel.add(Dense(50, activation='relu',W_regularizer=l2(0.01)))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70000 samples, validate on 30000 samples\n",
      "Epoch 1/5\n",
      "1496s - loss: 0.0980 - acc: 0.9735 - val_loss: 0.1331 - val_acc: 0.9704\n",
      "Epoch 2/5\n",
      "1489s - loss: 0.0896 - acc: 0.9760 - val_loss: 0.1266 - val_acc: 0.9703\n",
      "Epoch 3/5\n",
      "1487s - loss: 0.0856 - acc: 0.9767 - val_loss: 0.1173 - val_acc: 0.9731\n",
      "Epoch 4/5\n",
      "1488s - loss: 0.0807 - acc: 0.9785 - val_loss: 0.1205 - val_acc: 0.9736\n",
      "Epoch 5/5\n",
      "1487s - loss: 0.0784 - acc: 0.9795 - val_loss: 0.1284 - val_acc: 0.9704\n",
      "Baseline Error: 2.96%\n"
     ]
    }
   ],
   "source": [
    "model = larger_model()\n",
    "#model.load_weights(\"weights4_layers_updated_11layer_9700_wts.h5\",by_name=False)\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=5, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
    "#model.save(\"weights4_layers_updated_11layer_part3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take test data and predict output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xPred = numpy.fromfile('dataset/test_x.bin', dtype='uint8')\n",
    "xPred = xPred.reshape((20000,60,60))\n",
    "xPred[xPred<255] = 0\n",
    "xPred = xPred/ 255\n",
    "#xPred[xPred<1] = -1\n",
    "xPred=xPred.reshape(xPred.shape[0],1,60,60).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scipy.misc.imshow(xPred[19962]) # to visualize only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can save the model and reuse it for future purposes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"weights4_layers_updated_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"weights4_layers_updated_11layer_part2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"weights4_layers_updated_11layer_9704_wts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights4_layers_wts.h5\",by_name=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xPred.shape\n",
    "predictions = model.predict(xPred,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalpred=[]\n",
    "for i in predictions:\n",
    "    finalpred.append([j for j,z in enumerate(i) if z == max(i)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final output into a file as per the required format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "predictionFileName = \"Predictions4layers_updated_11layer_9700.csv\"\n",
    "result = pd.DataFrame(columns=('Id','Prediction'))\n",
    "count = 0\n",
    "for i in finalpred:\n",
    "    y = \"%d\"%count\n",
    "    value = \"%d\"%i[0]\n",
    "    result.loc[count]=[y,value]\n",
    "    count+=1\n",
    "result.to_csv(predictionFileName,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"finalpred_modified.csv\", \"wb\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(finalpred[0:15000])\n",
    "\n",
    "with open(\"finalpred0.8_modified1.csv\", \"wb\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(finalpred[15000:20000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
